# Hate Speech Detection - Transformer-basiertes Modell fÃ¼r Deutsch und Schweizerdeutsch

Ein umfassendes Projekt zur Erkennung von Hate Speech in deutschen und schweizerdeutschen Texten mit Hilfe von Transformer-Modellen.

## ğŸ“‹ Inhaltsverzeichnis

- [Ãœberblick](#Ã¼berblick)
- [Projektstruktur](#projektstruktur)
- [Daten](#daten)
- [Notebooks](#notebooks)
- [Installation](#installation)
- [Verwendung](#verwendung)
- [Modelle](#modelle)
- [Ergebnisse](#ergebnisse)
- [Deployment](#deployment)

## ğŸ¯ Ãœberblick

Dieses Projekt implementiert ein Transformer-basiertes Modell zur Klassifikation von Hate Speech in deutschen und schweizerdeutschen Texten. Das Modell basiert auf `deepset/gbert-base` und wurde auf einem speziell aufbereiteten Datensatz trainiert.

### Hauptfunktionen

- **Transformer-basierte Klassifikation**: Verwendet `gbert-base` fÃ¼r die Hate Speech Erkennung
- **Umfassende Evaluation**: Confusion Matrix, ROC Curve, Precision-Recall Curve
- **Bias-Screening**: Analyse der Modell-Performance fÃ¼r verschiedene demografische Gruppen
- **Active Learning**: Export von unsicheren Vorhersagen fÃ¼r manuelle Annotation
- **Explainability**: SHAP-basierte ErklÃ¤rungen fÃ¼r Modellvorhersagen
- **Deployment**: ONNX-Export fÃ¼r Produktionseinsatz

## ğŸ“ Projektstruktur

```
KETE/
â”œâ”€â”€ data/                          # DatensÃ¤tze
â”‚   â”œâ”€â”€ de_hf_112024.csv          # Original-Datensatz
â”‚   â”œâ”€â”€ de_hf_112024_train.csv    # Trainingsdatensatz (80%)
â”‚   â”œâ”€â”€ de_hf_112024_val.csv      # Validierungsdatensatz (5%)
â”‚   â”œâ”€â”€ de_hf_112024_test.csv     # Testdatensatz (20%)
â”‚   â””â”€â”€ vulgaer.txt               # VulgÃ¤rwÃ¶rter-Liste
â”‚
â”œâ”€â”€ notebook/                      # Jupyter Notebooks
â”‚   â”œâ”€â”€ hateSpeeech_splitData.ipynb    # Datenaufbereitung und Split
â”‚   â”œâ”€â”€ hateSpeech_trainmodel.ipynb    # Modelltraining
â”‚   â”œâ”€â”€ hateSpeech_validate.ipynb      # Validierung und Evaluation
â”‚   â””â”€â”€ results_*/                # Trainingsergebnisse
â”‚       â”œâ”€â”€ final_model/          # Finales trainiertes Modell
â”‚       â”œâ”€â”€ checkpoint-*/        # Training-Checkpoints
â”‚       â””â”€â”€ validation_results/  # Validierungsergebnisse
â”‚
â”œâ”€â”€ lambda-hatespeech/            # AWS Lambda Deployment
â”‚   â”œâ”€â”€ index.ts                  # Lambda Handler
â”‚   â””â”€â”€ model/                    # ONNX-Modell fÃ¼r Lambda
â”‚
â”œâ”€â”€ modelsagemaker/               # SageMaker Deployment
â”‚   â”œâ”€â”€ code/                     # Inference-Code
â”‚   â””â”€â”€ model.ckpt                # SageMaker-Modell
â”‚
â””â”€â”€ dokumentation/                # Dokumentationsbilder
```

## ğŸ“Š Daten

### Datensatz: `de_hf_112024.csv`

Der Hauptdatensatz enthÃ¤lt deutsche und schweizerdeutsche Texte mit Labels fÃ¼r Hate Speech.

**Spalten:**
- `text`: Der zu klassifizierende Text
- `labels`: BinÃ¤res Label (0 = Non-Hate, 1 = Hate Speech)

**Aufteilung:**
- **Training**: 80% (ca. 39.000 Samples)
- **Validation**: 5% (ca. 2.500 Samples)
- **Test**: 20% (ca. 9.800 Samples)

Die Aufteilung erfolgt stratifiziert, um die Label-Verteilung in allen Sets zu erhalten.

### Datenaufbereitung

1. **Filterung**: Nur EintrÃ¤ge mit Labels 0 oder 1 werden behalten
2. **Bereinigung**: Entfernung von NaN-Werten
3. **Split**: Stratifizierte Aufteilung in Train/Val/Test

## ğŸ““ Notebooks

### 1. `hateSpeeech_splitData.ipynb`

**Zweck**: Datenaufbereitung und Aufteilung in Train/Val/Test-Sets

**Funktionen:**
- LÃ¤dt den Original-Datensatz `de_hf_112024.csv`
- Filtert nach Labels 0 und 1
- FÃ¼hrt stratifizierten Split durch (5% Val, Rest 80/20 Train/Test)
- Speichert die aufgeteilten DatensÃ¤tze als CSV

**Ausgabe:**
- `data/de_hf_112024_train.csv`
- `data/de_hf_112024_val.csv`
- `data/de_hf_112024_test.csv`

### 2. `hateSpeech_trainmodel.ipynb`

**Zweck**: Training des Transformer-Modells

**Funktionen:**
- **Setup**: Installation von Paketen, Initialisierung
- **Daten laden**: LÃ¤dt Train- und Test-DatensÃ¤tze
- **Tokenisierung**: Verwendet `gbert-base` Tokenizer
- **Modell-Training**: 
  - Base Model: `deepset/gbert-base`
  - Training mit Early Stopping
  - Mixed Precision Training (CUDA)
  - Evaluation auf Testdaten
- **ONNX-Export**: Exportiert Modell fÃ¼r Produktion
- **Bias-Screening**: Analysiert Performance fÃ¼r verschiedene Gruppen
- **Active Learning**: Exportiert unsichere Vorhersagen
- **SHAP Explainability**: ErklÃ¤rt Modellvorhersagen

**Ausgabe:**
- `results_*/final_model/`: Finales trainiertes Modell
- `results_*/model.onnx`: ONNX-Export
- `results_*/active_learning_*.csv`: Active Learning Exports
- `results_*/model_card_*.json`: Modell-Metadaten

### 3. `hateSpeech_validate.ipynb`

**Zweck**: Umfassende Validierung und Evaluation des trainierten Modells

**Funktionen:**
- LÃ¤dt das trainierte Modell
- Erstellt Vorhersagen auf Validierungsdatensatz
- **Metriken**: Accuracy, Precision, Recall, F1, ROC AUC
- **Visualisierungen**:
  - Confusion Matrix (2 Varianten)
  - ROC Curve
  - Precision-Recall Curve
  - Metriken-Bar Charts
  - Wahrscheinlichkeitsverteilungen
  - Fehleranalyse
- **Fehleranalyse**: Identifiziert False Positives/Negatives
- **Export**: Speichert alle Ergebnisse als CSV

**Ausgabe:**
- `validation_results/validation_summary.csv`: Zusammenfassung der Metriken
- `validation_results/validation_predictions.csv`: Alle Vorhersagen
- `validation_results/false_positives.csv`: Falsch Positive Beispiele
- `validation_results/false_negatives.csv`: Falsch Negative Beispiele

## ğŸš€ Installation

### Voraussetzungen

- Python 3.8+
- Jupyter Notebook
- CUDA-fÃ¤hige GPU (empfohlen, aber nicht erforderlich)

### Pakete installieren

```bash
pip install transformers datasets accelerate torch shap scikit-learn pandas matplotlib seaborn tf-keras
```

FÃ¼r ONNX-Export:
```bash
pip install optimum[onnxruntime] onnxruntime onnxscript
```

## ğŸ’» Verwendung

### 1. Datenaufbereitung

```bash
# Ã–ffne das Notebook
jupyter notebook notebook/hateSpeeech_splitData.ipynb

# FÃ¼hre alle Zellen aus
# Dies erstellt die Train/Val/Test-Splits
```

### 2. Modelltraining

```bash
# Ã–ffne das Training-Notebook
jupyter notebook notebook/hateSpeech_trainmodel.ipynb

# FÃ¼hre alle Zellen der Reihe nach aus
# Das Training kann mehrere Stunden dauern (abhÃ¤ngig von GPU)
```

**Wichtige Parameter:**
- `BASE_MODEL_NAME`: `"deepset/gbert-base"`
- `MAX_LEN`: 512 (maximale SequenzlÃ¤nge)
- `BATCH_SIZE`: 16 (kann je nach GPU angepasst werden)
- `LEARNING_RATE`: 2e-5
- `NUM_EPOCHS`: 5

### 3. Validierung

```bash
# Ã–ffne das Validierungs-Notebook
jupyter notebook notebook/hateSpeech_validate.ipynb

# FÃ¼hre alle Zellen aus
# Dies erstellt alle Visualisierungen und Metriken
```

## ğŸ¤– Modelle

### Base Model: `deepset/gbert-base`

- **Architektur**: BERT-basiert, speziell fÃ¼r Deutsch trainiert
- **Parameter**: ~110 Millionen
- **Tokenisierung**: SentencePiece
- **Maximale SequenzlÃ¤nge**: 512 Tokens

### Training

- **Optimizer**: AdamW
- **Learning Rate**: 2e-5 mit Linear Decay
- **Warmup Steps**: 500
- **Early Stopping**: Basierend auf Validation Loss
- **Mixed Precision**: FP16 (wenn CUDA verfÃ¼gbar)

### Modellformate

1. **PyTorch** (`model.safetensors`): FÃ¼r weitere Training/Feintuning
2. **ONNX** (`model.onnx`): FÃ¼r Produktionseinsatz
3. **HuggingFace** (`final_model/`): Standard HuggingFace Format

## ğŸ“ˆ Ergebnisse

### Metriken (Beispiel)

Die genauen Metriken hÃ¤ngen vom trainierten Modell ab. Typische Werte:

- **Accuracy**: ~92-95%
- **F1-Score (Weighted)**: ~0.85-0.90
- **ROC AUC**: ~0.90-0.95
- **Precision (Hate Speech)**: ~0.70-0.80
- **Recall (Hate Speech)**: ~0.60-0.70

### Visualisierungen

Das Validierungsnotebook erstellt folgende Visualisierungen:

1. **Confusion Matrix**: Zeigt Klassifikationsfehler
2. **ROC Curve**: Zeigt Trade-off zwischen True/False Positive Rate
3. **Precision-Recall Curve**: Zeigt Trade-off zwischen Precision und Recall
4. **Metriken-Vergleich**: Bar Charts fÃ¼r alle Metriken
5. **Wahrscheinlichkeitsverteilung**: Histogramm und Boxplot
6. **Fehleranalyse**: Analyse von False Positives/Negatives

## ğŸš¢ Deployment

### AWS Lambda

Das Modell kann als AWS Lambda Function deployed werden:

```bash
cd lambda-hatespeech
npm install
# Modell muss in model/ Verzeichnis vorhanden sein
zip -r ../lambda-hatespeech.zip .
```

### SageMaker

Das Modell kann auch auf AWS SageMaker deployed werden:

```bash
# Modell muss als model.tar.gz gepackt sein
# Siehe modelsagemaker/ Verzeichnis fÃ¼r Inference-Code
```

### Lokale Verwendung

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Lade Modell
model_path = "notebook/results_*/final_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)
model.eval()

# Vorhersage
text = "Ihr Text hier"
inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
with torch.no_grad():
    outputs = model(**inputs)
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    predicted_class = predictions.argmax().item()
    confidence = predictions[0][predicted_class].item()

print(f"Klasse: {predicted_class}, Konfidenz: {confidence:.4f}")
```

## ğŸ” Bias-Screening

Das Modell analysiert die Performance fÃ¼r verschiedene Gruppen:

- **Ethnisch/Migration**: FlÃ¼chtling, Migrant, AuslÃ¤nder, etc.
- **Geschlecht/LGBTQ**: Frau, Mann, LGBTQ, etc.
- **Religion**: Christ, Muslim, Jude, etc.

Die Ergebnisse werden im Training-Notebook ausgegeben.

## ğŸ“š Active Learning

Das Modell exportiert automatisch:

1. **Unsichere Vorhersagen**: 300 Samples mit hÃ¶chster Unsicherheit
2. **Fehlerhafte Vorhersagen**: Alle falsch klassifizierten Samples

Diese kÃ¶nnen fÃ¼r manuelle Annotation und weiteres Training verwendet werden.

## ğŸ› ï¸ Troubleshooting

### Problem: `ModuleNotFoundError: No module named 'tf_keras'`

**LÃ¶sung**: Installiere `tf-keras`:
```bash
pip install tf-keras
```

### Problem: `optimum` nicht gefunden beim ONNX-Export

**LÃ¶sung**: Installiere optimum:
```bash
pip install optimum[onnxruntime]
```

### Problem: CUDA Out of Memory

**LÃ¶sung**: Reduziere `BATCH_SIZE` im Training-Notebook

### Problem: Modellpfad nicht gefunden

**LÃ¶sung**: Passe den `MODEL_PATH` im Validierungsnotebook an

## ğŸ“ Lizenz

Dieses Projekt wurde im Rahmen eines Master-Studiums erstellt.

## ğŸ‘¥ Autoren

- Erstellt fÃ¼r KETE (Key Technology)

## ğŸ“ Kontakt

Bei Fragen oder Problemen bitte ein Issue erstellen.

---

**Hinweis**: Dieses Modell ist fÃ¼r Forschungs- und Bildungszwecke gedacht. Bei Verwendung in Produktion sollten zusÃ¤tzliche Tests und Validierungen durchgefÃ¼hrt werden.

